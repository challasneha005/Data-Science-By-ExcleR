{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e380f6dd-b592-438d-9a4e-bb9322725fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\shiva\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\shiva\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\shiva\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shiva\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shiva\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddf96faf-9c00-4125-b416-68dd6eb8865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\shiva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003384c-46b4-4254-9504-0e5ad62d4cee",
   "metadata": {},
   "source": [
    "#### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831f152-59e4-47b2-945c-1bca53945682",
   "metadata": {},
   "source": [
    "#### Convert the text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86cba3bc-80b6-4d1a-8e05-5a868ba1b868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Congratulations! You've won $1000 in cash.Call me now!, The time is very short\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Congratulations! You've won $1000 in cash.Call me now!, The time is very short\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d27ae718-945b-49b7-9449-46ee8381d45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"congratulations! you've won $1000 in cash.call me now!, the time is very short\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to lower case\n",
    "text = text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906fad5-85c9-4ea4-b6dc-6fe48769da9c",
   "metadata": {},
   "source": [
    "#### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "223889eb-e6e9-4444-8b2b-673a37773e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations youve won 1000 in cashcall me now the time is very short\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d999e-b848-4715-a14d-9ee61310eb3b",
   "metadata": {},
   "source": [
    "#### Remove any digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dce99bf1-1128-48f3-b7bd-e5091de04db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratulations youve won  in cashcall me now the time is very short'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # regular expression library\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36392314-31e7-4e70-9f3e-23a4db98aa86",
   "metadata": {},
   "source": [
    "### Split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "914c32b7-e1f9-467a-a16b-8eb2ed943f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['congratulations',\n",
       " 'youve',\n",
       " 'won',\n",
       " 'in',\n",
       " 'cashcall',\n",
       " 'me',\n",
       " 'now',\n",
       " 'the',\n",
       " 'time',\n",
       " 'is',\n",
       " 'very',\n",
       " 'short']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into tokens / words using split() methods\n",
    "text.split()    # A list of tokens is created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1f9d0-d30f-418b-a54b-2b2622d164bb",
   "metadata": {},
   "source": [
    "#### Convert the text to word tokens using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64fecb4e-4689-432b-8bc2-b5660348d07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['congratulations',\n",
       "  'youve',\n",
       "  'won',\n",
       "  'in',\n",
       "  'cashcall',\n",
       "  'me',\n",
       "  'now',\n",
       "  'the',\n",
       "  'time',\n",
       "  'is',\n",
       "  'very',\n",
       "  'short'],\n",
       " 12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# text = \"Congratulations! You've won $1000 in cash.Call me now!, The time is very short\"\n",
    "tokens = word_tokenize(text)\n",
    "tokens,len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d0d9e-e9a1-45b1-b2df-6fc4dd51f6fe",
   "metadata": {},
   "source": [
    "#### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a18a832-2562-42e7-9d0c-468409deefa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "{\"wasn't\", 'theirs', 'mightn', 'isn', \"couldn't\", 'his', \"should've\", 'why', \"she'd\", \"we're\", \"doesn't\", 'are', 'as', 'all', 'our', 'y', 'ourselves', 'than', 'whom', 'an', \"i'd\", 'above', 'further', 'more', 'o', 'itself', 'before', 'and', \"aren't\", 'their', 'with', 'or', 'any', 'only', 'me', 'once', 'up', 'shan', \"you're\", 'here', \"needn't\", 'who', 'each', 'from', \"haven't\", \"she'll\", 'some', 'did', \"we'd\", \"you'd\", \"isn't\", 'them', 'own', 'its', 'on', 'by', \"they're\", 'below', 'him', 'about', 'doing', \"he's\", 'ain', 'against', 'but', 'she', 'these', 'then', 'i', 'm', 'themselves', 'until', 're', 'for', 'aren', 'while', \"you'll\", \"it's\", \"you've\", 'd', 'during', 'it', 'couldn', 'doesn', 'yourself', 'because', 'does', 'down', 'in', 'that', \"it'd\", 'yourselves', 'a', 'he', \"he'll\", \"he'd\", 'now', 'they', 'myself', 'again', 'just', \"shouldn't\", 'such', 'the', \"won't\", 'same', 'how', 'have', \"hadn't\", 'am', 'll', 'yours', 'should', 'out', 'shouldn', 'very', 'was', \"i'm\", \"they'd\", \"didn't\", 'been', 'being', \"it'll\", 'ours', 'through', 'under', 'which', 'when', 'ma', 'over', \"shan't\", 'had', 'will', 'mustn', 'needn', \"i'll\", 'hers', 'your', \"they'll\", 'between', 'few', 'most', 'off', 'hadn', 'has', \"she's\", 'we', \"wouldn't\", 'herself', 'wasn', 'my', 'haven', 'weren', 'her', 'after', \"i've\", 'no', 'of', 'don', 'is', 'himself', \"we'll\", 'didn', 'there', 'having', \"mustn't\", \"weren't\", 'at', 's', 'be', 'to', 'do', 've', 'what', 't', \"that'll\", 'were', 'can', 'you', \"they've\", 'won', 'wouldn', \"we've\", 'if', 'not', 'hasn', 'so', 'this', 'where', \"hasn't\", \"mightn't\", 'nor', 'those', 'both', 'too', 'other', \"don't\", 'into'}\n"
     ]
    }
   ],
   "source": [
    "# Import stop words from nltk and print them\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "705bcf02-17a2-4015-b137-673f20ecff11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['congratulations', 'youve', 'cashcall', 'time', 'short']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words from the text\n",
    "filtered_tokens = [word for word in tokens \\\n",
    "                        if word not in stop_words]\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c1f48-cdee-446d-91a2-52e6470c8f7e",
   "metadata": {},
   "source": [
    "#### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f609f5f3-7543-4ce5-9545-3eeda493bb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['congratulation', 'youve', 'cashcall', 'time', 'short']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform lemmatization of text\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for \\\n",
    "                    word in filtered_tokens]\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "206c32e8-492c-4b7b-8c56-763424c1764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['congratul', 'youv', 'cashcal', 'time', 'short']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(word) for word in filtered_tokens]\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ebf525-ce2d-4304-977b-0abc2c8a4c4f",
   "metadata": {},
   "source": [
    "#### Join the lemmatized tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "348be053-416f-4f4c-8d8f-f0d574efc64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratulation youve 1000 cash call time short'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = ' '.join(lemmatized)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d55d59-3a7a-4e6d-a4db-008d78f4a77d",
   "metadata": {},
   "source": [
    "#### All of the above operations of text preprocessing clubbed into a user defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3ec36b4-04e3-49b9-b82d-e202793ddfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shiva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shiva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shiva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'congratulation youve cash call'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "preprocess_text(\"Congratulations! You've won $1000 in cash. Call now!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016403b1-5271-4498-a8b9-53090ab7e938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
